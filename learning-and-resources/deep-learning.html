
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Deep Learning &#8212; NeuroPoly Lab Manual</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/theme.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NeuroPoly Lab Manual</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   üè† Lab Manual
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../onboarding/README.html">
   <span>
    üëã
   </span>
   Onboarding
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/getting-started.html">
     Getting Started
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/accounts.html">
     Accounts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/campus-access.html">
     Campus Access
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/infrastructure.html">
     Infrastructure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/dropbox-google-drive.html">
     Dropbox/Google Drive
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/computer-setup.html">
     Computer Setup
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/developer-setup.html">
     Developer Setup
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/consultants-ra.html">
     Consultants and RA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../onboarding/acronyms-jargon.html">
     Acronyms &amp; Jargon
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../agenda-and-calendar.html">
   <span>
    üìÖ
   </span>
   Calendar
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../mri-scanning/README.html">
   <span>
    üß≤
   </span>
   MRI Scanning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../mri-scanning/unf-3t-prisma.html">
     UNF (3T Prisma)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mri-scanning/mni-mcgill-7t-terra.html">
     MNI/McGill (7T Terra)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../mri-scanning/mhi-7t-agilent.html">
     MHI (7T Agilent)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../mri-scanning/coils/README.html">
     Coils
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../mri-scanning/coils/3d-printing/README.html">
       3D Printing
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../mri-scanning/coils/3d-printing/octoprint.html">
         OctoPrint
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../mri-scanning/coils/faq.html">
       FAQ
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../mri-scanning/coils/pcb-manufacturing.html">
       PCB Manufacturing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../mri-scanning/coils/cnc-machine-genmitsu-3018-prover.html">
       CNC machine - Genmitsu 3018-PROVer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../mri-scanning/phantoms/README.html">
     Phantoms
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../mri-scanning/phantoms/phantom-recipes-for-mri.html">
       Phantom Recipes for MRI
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../writing-articles.html">
   <span>
    ‚úçÔ∏è
   </span>
   Academic Writing
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../computing-resources/README.html">
   <span>
    üñ•
   </span>
   Computing Resources
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../computing-resources/neuropoly/README.html">
     NeuroPoly
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../computing-resources/neuropoly/data/README.html">
       Data
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../computing-resources/neuropoly/data/home.html">
         /home
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../computing-resources/neuropoly/data/git-datasets.html">
         <code class="docutils literal notranslate">
          <span class="pre">
           data
          </span>
         </code>
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../computing-resources/neuropoly/data/git-annex.html">
         git-annex
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../computing-resources/neuropoly/data/duke.html">
         <code class="docutils literal notranslate">
          <span class="pre">
           duke
          </span>
         </code>
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../computing-resources/neuropoly/data/django.html">
         <code class="docutils literal notranslate">
          <span class="pre">
           django
          </span>
         </code>
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../computing-resources/neuropoly/cpus2.html">
       CPUS2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../computing-resources/neuropoly/gpus.html">
       GPUs
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../computing-resources/compute-canada.html">
     Compute Canada
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../computing-resources/clusters-at-criugm.html">
     CRIUGM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../computing-resources/printer.html">
     <span>
      üñ®
     </span>
     Printer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../software-development/README.html">
   <span>
    üêç
   </span>
   Software Development
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/bash-shell/README.html">
     Bash/Shell
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/bash-shell/script.html">
       Script
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../software-development/git.html">
     git &amp; Github
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../software-development/untitled.html">
     NeuroPoly Packages &amp; Collaborations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/os-guides/README.html">
     OS Guides
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/os-guides/linux.html">
       Linux
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/os-guides/macosx.html">
       MacOSX
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../software-development/contributing.html">
     Contributing Guidelines
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/misc/README.html">
     Other Software &amp; Tools
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../software-development/misc/virtual-machines/README.html">
       Virtual Machines
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/misc/virtual-machines/virtualbox.html">
         VirtualBox
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/misc/virtual-machines/vagrant.html">
         Vagrant
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/bitbucket.html">
       BitBucket
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../software-development/misc/docker/README.html">
       Docker
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/misc/docker/docker-for-deep-learning.html">
         Docker for Deep Learning
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/dropbox.html">
       Dropbox
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/jekyll.html">
       Jekyll
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/microsoft-word.html">
       Microsoft Word
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/openneuro.html">
       OpenNeuro
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/git-and-github.html">
       Git &amp; GitHub
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/sketchup.html">
       Sketchup
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/misc/xquartz.html">
       XQuartz
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/programming-languages/README.html">
     Programming Languages
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/programming-languages/python.html">
       Python
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/programming-languages/matlab.html">
       MATLAB
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../software-development/programming-languages/c%2B%2B/README.html">
       C++
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/programming-languages/c%2B%2B/installation-of-vtk-and-itk-on-mac-os-x.html">
         Installation of VTK and ITK on Mac OS X
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/programming-languages/c%2B%2B/using-xcode.html">
         Using XCode
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/image-processing-software/README.html">
     Image Processing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/advanced-normalization-tools-ants.html">
       Advanced Normalization Tools (ANTs)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/anima.html">
       Anima
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/diffusion-simulator.html">
       Diffusion Simulator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/freesurfer.html">
       FreeSurfer
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../software-development/image-processing-software/fsl/README.html">
       FSL
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../software-development/image-processing-software/fsl/fsleyes.html">
         FSLeyes
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/itk-snap.html">
       ITK-SNAP
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/nifti.html">
       NIfTI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/openneuro-cli.html">
       OpenNeuro CLI
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/image-processing-software/osirix.html">
       OsiriX
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../software-development/deep-learning/README.html">
     Deep Learning
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/deep-learning/cuda.html">
       CUDA
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/deep-learning/tensorflow.html">
       Tensorflow
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/deep-learning/conditional-random-fields-crf.html">
       Conditional Random Fields (CRF)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/deep-learning/restricted-boltzmann-machines.html">
       Restricted Boltzmann Machines (RBM)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../software-development/deep-learning/misc.html">
       Misc
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../courses.html">
   <span>
    üéì
   </span>
   University Courses
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../bibliography/README.html">
   <span>
    üìö
   </span>
   Bibliography
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../bibliography/deep-learning.html">
     Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bibliography/histology.html">
     Histology
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bibliography/untitled.html">
     MRI
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bibliography/shared-paperpile-folder.html">
     Paperpile Folder
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../conferences.html">
   <span>
    ‚úàÔ∏è
   </span>
   Conferences
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ideas-for-cool-projects.html">
   <span>
    üí°
   </span>
   Ideas for Cool Projects
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../practical-information/README.html">
   <span>
    üìé
   </span>
   Practical Information
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../practical-information/visa.html">
     VISAs and Work Permits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../practical-information/moving-to-montreal.html">
     <span>
      üá®üá¶
     </span>
     Living in Montreal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../practical-information/scholarships-and-bursaries.html">
     Scholarships &amp; Bursaries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../practical-information/purchasing-hardware-and-lab-supplies.html">
     Purchasing Supplies
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contact.html">
   <span>
    üìû
   </span>
   Contact
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">


<!-- only one Github button activated, so collapse it into the main button, saving a click for users -->
        <a class="edit-button" href="https://github.com/neuropoly/intranet.neuro.polymtl.ca/edit/master/learning-and-resources/deep-learning.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fab fa-github"></i></button></a>


</div>


            <!-- Full screen (wrap in <a> to have style consistency -->

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Page Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-learning-resources">
   Deep Learning Resources
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-learning-applied-to-medical-analysis">
   Deep Learning Applied to Medical Analysis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-learning-applied-to-mri">
   Deep Learning Applied to MRI
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cnns">
   CNNs
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#u-net">
   U-Net
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spinal-cord-segmentation-on-mri-data">
   Spinal Cord Segmentation on MRI Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continual-learning">
   Continual Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-wise-linear-modulation-film">
   Feature-wise Linear Modulation (FiLM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gans">
   GANs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gans-for-synthetic-medical-data">
     GANs for Synthetic Medical Data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#few-shot-learning-and-meta-learning">
   Few-shot Learning and Meta-Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#domain-adaptation">
   <strong>
    Domain Adaptation:
   </strong>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#domain-adaptation-for-medical-imaging">
     <strong>
      Domain Adaptation for Medical Imaging:
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-odes">
   <strong>
    Neural ODEs:
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#anatomical-priors">
   <strong>
    Anatomical Priors:
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#physics-informed-deep-learning">
   <strong>
    Physics Informed Deep Learning:
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mixup">
   <strong>
    MixUp
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#uncertainty">
   <strong>
    Uncertainty
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inter-rater">
   <strong>
    Inter-rater
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#out-of-distribution-ood">
   <strong>
    Out of Distribution (OOD)
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#longitudinal-ms-lesion-segmentation">
   Longitudinal MS Lesion Segmentation
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="deep-learning">
<h1>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline">¬∂</a></h1>
<div class="section" id="deep-learning-resources">
<h2>Deep Learning Resources<a class="headerlink" href="#deep-learning-resources" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=53YvP6gdD7U">Deep Learning State of the Art (2019) - MIT (Youtube Video)</a></p></li>
</ul>
</div>
<div class="section" id="deep-learning-applied-to-medical-analysis">
<h2>Deep Learning Applied to Medical Analysis<a class="headerlink" href="#deep-learning-applied-to-medical-analysis" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S1361841517301135">A survey on deep learning in medical image analysis</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=2_Jv11VpOF4">Deep Learning in Medical Imaging - Ben Glocker, Imperial College London (YouTube Video)</a></p></li>
</ul>
</div>
<div class="section" id="deep-learning-applied-to-mri">
<h2>Deep Learning Applied to MRI<a class="headerlink" href="#deep-learning-applied-to-mri" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0939388918301181">An overview of deep learning in medical imaging focusing on MRI</a></p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0933365716305206">Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review</a></p></li>
</ul>
</div>
<div class="section" id="cnns">
<h2>CNNs<a class="headerlink" href="#cnns" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://e2eml.school/how_convolutional_neural_networks_work.html">How do Convolutional Neural Networks work?</a></p></li>
<li><p><a class="reference external" href="https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8">The best explanation of Convolutional Neural Networks on the Internet!</a></p></li>
<li><p><a class="reference external" href="https://algobeans.com/2016/01/26/introduction-to-convolutional-neural-network/">Convolutional Neural Networks (CNN) Introduction</a></p></li>
<li><p><a class="reference external" href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/">A Beginner‚Äôs Guide to Understanding Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://cs231n.github.io/convolutional-networks/#overview">CS231n Lecture Notes</a></p></li>
</ul>
</div>
<div class="section" id="u-net">
<h2>U-Net<a class="headerlink" href="#u-net" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1505.04597.pdf">arXiv: U-Net: Convolutional Networks for Biomedical Image Segmentation (Original Paper)</a></p></li>
<li><p><a class="reference external" href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">Presentation from the Authors</a></p></li>
<li><p><a class="reference external" href="https://spark-in.me/post/unet-adventures-part-one-getting-acquainted-with-unet">Getting acquainted with U-NET architecture + some keras shortcuts</a></p></li>
<li><p><a class="reference external" href="https://medium.com/vooban-ai/satellite-image-segmentation-a-workflow-with-u-net-7ff992b2a56e">Satellite Image Segmentation: a Workflow with U-Net</a></p></li>
</ul>
</div>
<div class="section" id="spinal-cord-segmentation-on-mri-data">
<h2>Spinal Cord Segmentation on MRI Data<a class="headerlink" href="#spinal-cord-segmentation-on-mri-data" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007/s10334-015-0507-2">Segmentation of the human spinal cord</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1710.01269">Spinal cord gray matter segmentation using deep dilated convolutions</a></p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S1053811918319578">Automatic segmentation of the spinal cord and intramedullary multiple sclerosis lesions with convolutional neural networks</a></p></li>
</ul>
</div>
<div class="section" id="continual-learning">
<h2>Continual Learning<a class="headerlink" href="#continual-learning" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/optimass/continual_learning_papers">Continual Learning Papers</a></p></li>
<li><p><a class="reference external" href="https://sites.google.com/view/ift6760-b2021/topics-and-papers?authuser=0">Continual Learning: Towards ‚ÄúBroad‚Äù AI</a></p></li>
</ul>
</div>
<div class="section" id="feature-wise-linear-modulation-film">
<h2>Feature-wise Linear Modulation (FiLM)<a class="headerlink" href="#feature-wise-linear-modulation-film" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1709.07871.pdf">FiLM: Visual Reasoning with a General Conditioning Layer</a></p>
<ul>
<li><p><a class="reference external" href="https://github.com/ethanjperez/film">GitHub: ethanjperez/film</a></p></li>
<li><p><a class="reference external" href="https://github.com/rosinality/film-pytorch">GitHub: rosinality/film-pytorch</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/contrib/blob/master/torchcontrib/nn/functional.py">GitHub: pytorch/contrib/torchcontrib/nn/functional.py</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/contrib/blob/5b7961ab0368c4c61872e6fe96db581afb453f1e/torchcontrib/nn/modules/linear.py">GitHub: pytorch/contrib/torchcontrib/nn/modules/linear.py</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://distill.pub/2018/feature-wise-transformations/">Feature-wise transformations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1802.01218.pdf">Efficient Video Object Segmentation via Network Modulation</a></p>
<ul>
<li><p><a class="reference external" href="https://github.com/linjieyangsc/video_seg">GitHub: linjieyangsc/video_seg</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1903.09467.pdf">Disentangled representation learning in cardiac image analysis</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1808.04000.pdf">Language Guided Fashion Image Manipulation with Feature-wise Transformations*</a></p></li>
<li><p><a class="reference external" href="https://openreview.net/pdf?id=S11Xr-3iM">Deep Multi-Class Segmentation Without Ground-Truth Labels</a></p></li>
<li><p><a class="reference external" href="https://github.com/ap229997/Neural-Toolbox-PyTorch/blob/master/film_layer.py">GitHub: ap229997/Neural-Toolbox-PyTorch/blob/master/film_layer.py</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1907.11150.pdf">Hetero-Modal Variational Encoder-Decoder for Joint Modality Completion and Segmentation</a></p></li>
</ul>
</div>
<div class="section" id="gans">
<h2>GANs<a class="headerlink" href="#gans" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://wiki.pathmind.com/generative-adversarial-network-gan">A Beginner‚Äôs Guide to Generative Adversarial Networks (GANs)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1406.2661.pdf">Generative Adversarial Nets</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29">Towards Data Science: Understanding GANs</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1606.03498.pdf">Improved Techniques for Training GANs</a></p></li>
</ul>
<div class="section" id="gans-for-synthetic-medical-data">
<h3>GANs for Synthetic Medical Data<a class="headerlink" href="#gans-for-synthetic-medical-data" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/document/8653423">https://ieeexplore.ieee.org/document/8653423</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1709.01872">arXiv: Synthetic Medical Images from Dual Generative Adversarial Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1708.00129">arXiv: Deep Generative Adversarial Neural Networks for Realistic Prostate Lesion MRI Synthesis</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1807.10225">arXiv: Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Networks</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8363576">https://ieeexplore.ieee.org/abstract/document/8363576</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1803.01229.pdf">arXiv: GAN-based Synthetic Medical Image Augmentation for increased CNN Performance in Liver Lesion Classification</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-319-66179-7_48">https://link.springer.com/chapter/10.1007/978-3-319-66179-7_48</a></p></li>
</ul>
</div>
</div>
<div class="section" id="few-shot-learning-and-meta-learning">
<h2>Few-shot Learning and Meta-Learning<a class="headerlink" href="#few-shot-learning-and-meta-learning" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://medium.com/quick-code/understanding-few-shot-learning-in-machine-learning-bede251a0f67">https://medium.com/quick-code/understanding-few-shot-learning-in-machine-learning-bede251a0f67</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1810.12241.pdf">Few-shot 3D multi-modal Medical Image Segmentation using Generative Adversarial Learning</a></p></li>
<li><p><a class="reference external" href="https://www.aclweb.org/anthology/D18-1352">Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces</a></p></li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/fd1a/b77141683469ed9f39440c7d442d027cbb59.pdf">Meta-Learning for Medical Image Classification</a></p></li>
<li><p><a class="reference external" href="http://thoth.inrialpes.fr/workshop/paiss2018/larochelle-metalearning.pdf">Generalizing from Few Examples with Meta-Learning</a></p></li>
<li><p><a class="reference external" href="http://delivery.acm.org/10.1145/3140000/3132650/p89-kim.pdf?ip=132.207.154.93&amp;id=3132650&amp;acc=ACTIVE%20SERVICE&amp;key=FD0067F557510FFB%2EC32CC723E17B05B2%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&amp;__acm__=1555353937_48424f064a407dbf7bc84ae703454e71">Few-shot Learning Using a Small-Sized Dataset of High-Resolution FUNDUS Images for Glaucoma Diagnosis</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1706.03466.pdf">Few-Shot Image Recognition by Predicting Parameters from Activations</a></p></li>
</ul>
</div>
<div class="section" id="domain-adaptation">
<h2><strong>Domain Adaptation:</strong><a class="headerlink" href="#domain-adaptation" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1702.05374.pdf">arXiv: Domain Adaptation for Visual Applications: A Comprehensive Survey</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1706.05208.pdf">arXiv: Self-ensembling for visual domain adaptation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1409.7495.pdf">arXiv: Unsupervised Domain Adaptation by Backpropagation ‚Üí gradient reversal layer</a></p></li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Tzeng_Adversarial_Discriminative_Domain_CVPR_2017_paper.pdf%20">Adversarial Discriminative Domain Adaptation</a></p></li>
<li><p><a class="reference external" href="http://www.jmlr.org/papers/volume17/15-239/15-239.pdf">JMLR: Domain-Adversarial Training of Neural Networks</a></p></li>
<li><p><a class="reference external" href="http://papers.nips.cc/paper/6360-learning-transferrable-representations-for-unsupervised-domain-adaptation.pdf">Learning Transferrable Representations for Unsupervised Domain Adaptation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1603.04779.pdf">arXiv: Revisiting Batch Normalization for Practical Domain Adaptation</a></p></li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Bousmalis_Unsupervised_Pixel-Level_Domain_CVPR_2017_paper.pdf">Unsupervised Pixel‚ÄìLevel Domain Adaptation with Generative Adversarial Networks</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8461682&amp;tag=1">Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1602.04889.pdf">arXiv: Unsupervised Domain Adaptation Using Approximate Label Matching</a></p></li>
</ul>
<div class="section" id="domain-adaptation-for-medical-imaging">
<h3><strong>Domain Adaptation for Medical Imaging:</strong><a class="headerlink" href="#domain-adaptation-for-medical-imaging" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1809.10486.pdf">arXiv: nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation</a></p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811919302034">Unsupervised domain adaptation for medical imaging segmentation with self-ensembling</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8363637">Domain Adaptation for Biomedical Image Segmentation Using Adversarial Training</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-59050-9_47.pdf">Unsupervised Domain Adaptation in Brain Lesion Segmentation with Adversarial Networks</a> (Reference given in the Mila talk about domain adaptation in MRI)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1807.04657.pdf">arXiv: Deep semi-supervised segmentation with weight-averaged consistency targets</a> (auth: Julien Cohen-Adad)</p></li>
<li><p><a class="reference external" href="http://jmai.amegroups.com/article/view/4659/html">Promises and limitations of deep learning for medical image segmentation</a> (auth: Julien Cohen-Adad)</p></li>
<li><p><a class="reference external" href="https://books.google.ca/books?id=o3dvDwAAQBAJ&amp;pg=PA14&amp;lpg=PA14&amp;dq=perone+cohen-adad+mean+teacher&amp;source=bl&amp;ots=nH6zParhLH&amp;sig=ACfU3U146YZVC2bPVRhKjfwayHhJZgzkEA&amp;hl=fr&amp;sa=X&amp;ved=2ahUKEwjrycXdutXhAhUBvVkKHRSqD38Q6AEwCnoECAgQAQ#v=onepage&amp;q=perone%20cohen-adad%20mean%20teacher&amp;f=false">Google Books: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support</a> (auth: Julien Cohen-Adad)</p></li>
<li><p><a class="reference external" href="https://github.com/neuropoly/domainadaptation">GitHub: neuropoly/domainadaptation</a></p></li>
</ul>
</div>
</div>
<div class="section" id="neural-odes">
<h2><strong>Neural ODEs:</strong><a class="headerlink" href="#neural-odes" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://papers.nips.cc/paper/7892-neural-ordinary-differential-equations.pdf">Neural Ordinary Differential Equations</a></p></li>
<li><p><a class="reference external" href="https://reader.elsevier.com/reader/sd/pii/S0021999117309014?token=73C63FA0F6BC4657747DBF5BA66DB7340CB0D2340C9C4460E5D3CE8FC3EE4B0A2FDF4E07AE758BA448FE80CEAD9F3D68">Hidden physics models: Machine learning of nonlinear partial differential equations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1804.07010.pdf">Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential Equations</a></p></li>
<li><p><a class="reference external" href="http://www.jmlr.org/papers/volume19/18-046/18-046.pdf">JMLR: Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations</a></p></li>
</ul>
</div>
<div class="section" id="anatomical-priors">
<h2><strong>Anatomical Priors:</strong><a class="headerlink" href="#anatomical-priors" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8363652">https://ieeexplore.ieee.org/abstract/document/8363652</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1909.08330.pdf">arXiv: Probabilistic Atlases to Enforce Topological Constraints</a></p></li>
</ul>
</div>
<div class="section" id="physics-informed-deep-learning">
<h2><strong>Physics Informed Deep Learning:</strong><a class="headerlink" href="#physics-informed-deep-learning" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1708.00588.pdf">arXiv: Hidden Physics Models: Machine Learning of Nonlinear Partial Differential Equations</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/document/8936238">Yaman 2019</a></p></li>
<li><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/31129303/">PubMed: PSACNN: Pulse sequence adaptive fast whole brain segmentation</a></p></li>
<li><p><a class="reference external" href="https://paperpile.com/shared/93BsPD">Paperpile: Physics-Informed Brain MRI Segmentation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1711.10561.pdf">arXiv: Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1711.10566.pdf">arXiv: Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1808.04327.pdf">arXiv: Hidden Fluid Mechanics: A Navier-Stokes Informed Deep Learning Framework for Assimilating Flow Visualization Data</a></p></li>
<li><p><a class="reference external" href="https://www.aaai.org/Conferences/AAAI/2017/PreliminaryPapers/12-Stewart-14967.pdf">Label-Free Supervision of Neural Networks with Physics and Domain Knowledge</a></p></li>
<li><p><a class="reference external" href="https://paperpile.com/app/p/6d2782e1-2c9d-0c45-998a-43c25e6d6328">AUTOmated pulse SEQuence generation (AUTOSEQ) and neural network decoding for fast quantitative MR parameter measurement using continuous and simultaneous RF transmit and receive</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1710.05267.pdf">arXiv: MR fingerprinting Deep RecOnstruction NEtwork (DRONE)</a></p></li>
<li><p><a class="reference external" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-126.pdf">Complex-valued Deep Learning with Applications to Magnetic Resonance Image Synthesis</a></p></li>
<li><p><a class="reference external" href="https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.13756">Technical Note: Simultaneous segmentation and relaxometry for MRI through multitask learning</a></p></li>
<li><p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.27969">Knee menisci segmentation and relaxometry of 3D ultrashort echo time cones MR imaging using attention U-Net with transfer learning</a></p></li>
<li><p><a class="reference external" href="https://paperpile.com/shared/Ahan9R">CIS522 UPenn Course: Physics Informed Deep learning</a></p></li>
</ul>
</div>
<div class="section" id="mixup">
<h2><strong>MixUp</strong><a class="headerlink" href="#mixup" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1710.09412.pdf">https://arxiv.org/pdf/1710.09412.pdf</a></p></li>
<li><p><a class="reference external" href="https://www.inference.vc/mixup-data-dependent-data-augmentation/">https://www.inference.vc/mixup-data-dependent-data-augmentation/</a></p></li>
<li><p><a class="reference external" href="https://forums.fast.ai/t/mixup-data-augmentation/22764">https://forums.fast.ai/t/mixup-data-augmentation/22764</a></p></li>
<li><p><a class="reference external" href="http://mlexplained.com/2019/06/02/papers-dissected-mixmatch-a-holistic-approach-to-semi-supervised-learning-and-unsupervised-data-augmentation-explained/">http://mlexplained.com/2019/06/02/papers-dissected-mixmatch-a-holistic-approach-to-semi-supervised-learning-and-unsupervised-data-augmentation-explained/</a></p></li>
</ul>
</div>
<div class="section" id="uncertainty">
<h2><strong>Uncertainty</strong><a class="headerlink" href="#uncertainty" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pubmed/23773521">PubMed: Improved inference in Bayesian segmentation using Monte Carlo sampling: application to hippocampal subfield volumetry</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-030-32251-9_59">Improving Uncertainty Estimation in Convolutional Neural Networks Using Inter-rater Agreement</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-030-33642-4_6">Exploring the Relationship Between Segmentation Uncertainty, Segmentation Performance and Inter-observer Variability with Probabilistic Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1506.02142.pdf">Dropout as a Bayesian Approximation</a> - For Epistemic Uncertainty</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1703.04977.pdf">What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?</a> - Unification of  Aleatoric and Epistemic Uncertainty</p></li>
<li><p><a class="reference external" href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html">What My Deep Model Doesn‚Äôt Know‚Ä¶</a></p></li>
</ul>
</div>
<div class="section" id="inter-rater">
<h2><strong>Inter-rater</strong><a class="headerlink" href="#inter-rater" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.11872">arXiv: The Worrisome Impact of an Inter-rater Bias on Neural Network Training</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1806.02562.pdf">arXiv: On the Effect of Inter-observer Variability for a Reliable Estimation of Uncertainty of Medical Image Segmentation</a></p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s41598-020-64803-w">Evaluating White Matter Lesion Segmentations with Refined S√∏rensen-Dice Analysis</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-030-32251-9_59">Improving Uncertainty Estimation in Convolutional Neural Networks Using Inter-rater Agreement</a></p></li>
</ul>
</div>
<div class="section" id="out-of-distribution-ood">
<h2><strong>Out of Distribution (OOD)</strong><a class="headerlink" href="#out-of-distribution-ood" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://openreview.net/forum?id=1ABDN92t49">Which MOoD Methods work? A Benchmark of Medical Out of Distribution Detection</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2004.06569">Improving Calibration and Out-of-Distribution Detection in Medical Image Segmentation with Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.06831">Detection and Retrieval of Out-of-Distribution Objects in Semantic Segmentation</a></p></li>
</ul>
</div>
<div class="section" id="longitudinal-ms-lesion-segmentation">
<h2>Longitudinal MS Lesion Segmentation<a class="headerlink" href="#longitudinal-ms-lesion-segmentation" title="Permalink to this headline">¬∂</a></h2>
<p>This is for the MS Challenge 2021.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S2213158220302825">Fully automated longitudinal segmentation of new or enlarged multiple sclerosis lesions using 3D convolutional neural networks</a></p></li>
<li><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811916307819">Longitudinal multiple sclerosis lesion segmentation: Resource and challenge</a></p></li>
</ul>
</div>
</div>


              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By NeuroPoly<br/>
        
            &copy; Copyright 2021, NeuroPoly.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>